import logging
import gc
import time

import torch
from torch.utils.data import DataLoader as PyTorchDataLoader
from analytics.utils.data import DataLoader
from .pbar import TrainProgress


LOG = logging.getLogger(__name__)


class MetricComputer(object):

    def __init__(self):
        self.instances = []
        # print(repr(self.instances))

    def update_state(self, *args):
        """Method of computing and update metric state"""
        for idx, _ in enumerate(self.instances):
            self.instances[idx].update_state(*args)

    def reset_state(self):
        """Method of reset metric states"""
        for idx, _ in enumerate(self.instances):
            self.instances[idx].reset_state()


class Trainer(object):
    """Base training implementation"""

    def __init__(
        self,
        train_dataset,
        valid_dataset=None,
        device=None,
        batch_size=32,
        n_workers=4,
        metric_classes=None,
        optim_rate=None,
        checkpoint=None,
        partial_ckp_rate=25,
        pbar_format=None,
        log_format=None,
    ):
        if metric_classes is None:
            metric_classes = {}
        if train_dataset is None:
            raise ValueError("Must be define a dataset.")

        self._train_dataset = train_dataset
        self._valid_dataset = valid_dataset
        self._device = device
        self._pbar_format = pbar_format  # if pbar_format \

        self._log_format = log_format
        self._optim_rate = optim_rate

        self.batch_size = batch_size
        self.checkpoint = checkpoint
        self.partial_ckp_rate = partial_ckp_rate
        self.n_workers = n_workers
        self.metric_classes = metric_classes
        self.callbacks = []
        # if self.checkpoint and self.checkpoint.is_available():
        #     self.checkpoint.load_latest()

        if not device:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        self.train_results = {}
        self.valid_results = {}
        self._metrics = {}

    def compile(self, *args, **kwargs):
        """Training compilation function

        This function is used to configure
        the training algorithm with the loss
        function and optimizer we will use.
        """
        raise NotImplemented

    def compute_metric(self, name,  *args):
        """
        This method allow to appy all available metrics
        on `y_pred` generated by the model and `y_true`
        provided from the dataset.

        :type name: `str`
        """
        if name not in self._metrics:
            raise IndexError("This name isn't associated to metric instances.")

        self._metrics[name].update_state(*args)

    def on_start_train(self):
        """Method executed on start train

        In this method, you can call `model.train()`.
        """
        pass

    def on_start_eval(self):
        """Method executed on start train

        In this method, you can call `model.eval()`.
        """
        pass

    def train_step(self, *args):
        """Training method of the model

        It's used to train model(s) on one batch
        of the dataset.
        """
        raise NotImplemented

    def estimate_step(self, *args):
        """Estimation method of the model

        It's used to estimate model(s) error
        on one batch of the dataset.
        """
        raise NotImplemented

    def optimize_step(self):
        """Optimization method of the model parameters

        It's used to make gradient descent of model(s)
        after estimation of loss some batch of the dataset.
        """
        raise NotImplemented

    def eval_step(self, *args):
        """Evaluation method of the model

        It's used to evaluate model(s) on one batch
        of the dataset.
        """
        raise NotImplemented

    def _run_callback(self, method):
        """Method to run method callback"""
        for cb in self.callbacks:
            if not hasattr(cb, method):
                continue

            if method == 'on_before_eval' and callable(cb.on_before_eval):
                cb.on_before_eval()
            elif method == 'on_epoch_end' and callable(cb.on_epoch_end):
                cb.on_epoch_end()
            elif method == 'on_train_end' and callable(cb.on_train_end):
                cb.on_train_end()

    @staticmethod
    def _update_result(results, result):
        """Method of updating result

        :param results: The list of result for each epoch.
        :param result: The result of the current epoch done.

        :type results: Dict[str, List[Any]]
        :type result: Dict[str, Any]
        :rtype: Dict[str, List[Any]]
        """
        if not result:
            return results

        for attr_name, value in result.items():
            if attr_name in results:
                results[attr_name].append(value)
            else:
                results[attr_name] = [value]

        return results  # we return updated results;

    @staticmethod
    def _update_result_with_metrics(results, metrics_dict):
        """Method of updating results with metrics results"""
        for attr_name, metric in metrics_dict.items():
            if attr_name in results:
                results[attr_name].append(metric.result())
            else:
                results[attr_name] = [metric.result()]

        return results

    def _get_metric_results(self):
        results = {}
        for name, metric_computer in self._metrics.items():
            for metric in metric_computer.instances:
                results[f"{name}_{metric.name}"] = metric.result()

        return results

    def _reset_metrics_state(self):
        for name in self._metrics:
            self._metrics[name].reset_state()

    def run(self, n_epochs=2, restart_epochs=False):
        """Training running method"""
        # We create an instance each metric in each
        # step (training, validation).
        for name, metric_classes in self.metric_classes.items():
            self._metrics[name] = MetricComputer()
            # self._metrics[name].instances = []
            # print(name)
            for metric_cls in metric_classes:
                self._metrics[name].instances.append(metric_cls())

        pbar = TrainProgress(length=0,
                             bins=34,
                             bchr='█',
                             empt='░',
                             lchr='',
                             rchr='',
                             pchr='|',
                             barf=self._pbar_format,
                             log_format=self._log_format,)
        start = 0
        prev_n_epochs = 0
        batch_index = 0
        batch_indices = None
        old_results = None
        old_metrics = None
        step = 'train'
        if self.checkpoint:
            self.checkpoint.put('train_results', {})
            self.checkpoint.put('valid_results', {})
            self.checkpoint.put('n_epochs', n_epochs)
            self.checkpoint.put('epoch', 0)
            self.checkpoint.put('batch_index', 0)
            self.checkpoint.put('batch_indices', None)
            self.checkpoint.put('tmp_results', None)
            self.checkpoint.put('tmp_metrics', None)
            self.checkpoint.put('training_step', 'train')
            if self.checkpoint.is_available():
                LOG.info("\033[92mCheckpoint detected.\033[0m")
                self.checkpoint.load_latest()
            else:
                self.checkpoint.save()

            self.train_results = self.checkpoint.get('train_results')
            self.valid_results = self.checkpoint.get('valid_results')
            prev_n_epochs = self.checkpoint.get('n_epochs')
            start = self.checkpoint.get('epoch')
            batch_index = self.checkpoint.get('batch_index', 0)
            batch_indices = self.checkpoint.get('batch_indices')
            old_results = self.checkpoint.get('tmp_results')
            old_metrics = self.checkpoint.get('tmp_metrics')
            step = self.checkpoint.get('training_step', 'train')

        valid_batch_indices = None
        train_batch_indices = None
        if step == 'train':
            train_batch_indices = batch_indices
        elif step == 'valid':
            valid_batch_indices = batch_indices

        train_loader = DataLoader(dataset=self._train_dataset,
                                  batch_size=self.batch_size,
                                  num_workers=self.n_workers,
                                  initial_batch_indices=train_batch_indices,
                                  shuffle=True)

        valid_loader = None
        if self._valid_dataset:
            valid_loader = DataLoader(dataset=self._valid_dataset,
                                      batch_size=self.batch_size,
                                      num_workers=self.n_workers,
                                      initial_batch_indices=valid_batch_indices,
                                      shuffle=False)

        def finalise_epoch(current_epoch):
            if self.checkpoint:
                pbar.log('message', 'saving...')
                self.checkpoint.put('epoch', current_epoch)
                self.checkpoint.put('n_epochs', n_epochs)
                self.checkpoint.save()

            pbar.log('message', 'DONE!')
            self._run_callback('on_epoch_end')
            pbar.finalise()
            pbar.reset()

        def partial_checkpoint(batch_index=0,
                               batch_indices=None,
                               results=None,
                               metrics=None,
                               step='train'):
            if self.checkpoint:
                self.checkpoint.put('batch_index', batch_index)
                self.checkpoint.put('batch_indices', batch_indices)
                self.checkpoint.put('tmp_results', results)
                self.checkpoint.put('tmp_metrics', metrics)
                self.checkpoint.put('training_step', step)
                self.checkpoint.partial_save()

            return batch_index, batch_indices, results, metrics, step

        def merge_result(old_result, curr_result):
            if not isinstance(old_result, dict) \
                    or not isinstance(curr_result, dict):
                return curr_result

            for key, value in old_result.items():
                if key in curr_result:
                    val1 = old_result[key]
                    val2 = curr_result[key]
                    curr_result[key] = (val1 + val2) / 2

            return curr_result

        if restart_epochs or start >= n_epochs or n_epochs != prev_n_epochs:
            start = 0

        for epoch in range(start, n_epochs):
            time.sleep(1)
            metrics = None
            results = None
            if step == 'train':
                pbar.length = len(train_loader)
                pbar.loginfo.update(dict(
                    epoch=(epoch+1),
                    n_epochs=n_epochs,
                    message='train...',
                ))

                pbar.log()
                self.on_start_train()

                train_loader.set_batch_index(batch_index)
                pbar.step(batch_index+1)

                if isinstance(old_metrics, dict):
                    pbar.loginfo.update(old_metrics)

                if isinstance(old_results, dict):
                    pbar.loginfo.update(old_results)

                for index, batch in enumerate(train_loader):
                    if not self._optim_rate:
                        results = self.train_step(*batch)
                    else:
                        results = self.estimate_step(*batch)
                        if (index % self._optim_rate) == 0:
                            self.optimize_step()

                    metrics = self._get_metric_results()

                    if old_metrics is not None or old_results is not None:
                        # if the old metric or result values are found,
                        # then we use then to merge its values with
                        # the current metric and result values.
                        # LOG.debug('old metrics found: ' + str(old_metrics))
                        # LOG.debug('old results found: ' + str(old_results))
                        metrics = merge_result(old_metrics, metrics)
                        results = merge_result(old_results, results)
                        old_metrics = None
                        old_results = None

                    pbar.loginfo.update(metrics)
                    pbar.log()
                    pbar.step(1)

                    if train_loader.batch_index % self.partial_ckp_rate == 0:
                        partial_checkpoint(train_loader.batch_index,
                                           train_loader.batch_indices,
                                           results,
                                           metrics,
                                           'train',
                                           )

                    if not isinstance(results, dict):
                        continue

                    pbar.loginfo.update(results)
                    pbar.log()

                self._update_result(self.train_results, results)
                self._update_result(self.train_results, metrics)
                self._reset_metrics_state()  # To reset metric state;

                returned = partial_checkpoint()
                batch_index = returned[0]
                batch_indices = returned[1]
                results = returned[2]
                metrics = returned[3]
                step = returned[4]

                # free memory of `train_loader`;
                # del train_loader
                # gc.collect()

            if not valid_loader:
                finalise_epoch(epoch + 1)
                continue
            
            step = 'valid'
            partial_checkpoint(step=step)
            
            if step == 'valid':
                pbar.log('message', 'train done!')
                pbar.finalise()
                pbar.reset()
                pbar.length = len(valid_loader)
                self._run_callback('on_before_eval')
                try:
                    pbar.loginfo.update(
                        dict(
                            epoch=(epoch + 1),
                            n_epochs=n_epochs,
                            message='eval...'
                        )
                    )
                    # self.pbar.log('epoch', (epoch+1))
                    # self.pbar.log('n_epochs', n_epochs)
                    # self.pbar.log('message', 'train...')
                    pbar.log()
                    self.on_start_eval()
                    with torch.no_grad():
                        valid_loader.set_batch_index(batch_index)
                        pbar.step(batch_index+1)

                        # Update progress bar with old metric and result
                        # values.
                        if isinstance(old_metrics, dict):
                            pbar.loginfo.update(old_metrics)

                        if isinstance(old_results, dict):
                            pbar.loginfo.update(old_results)

                        for index, batch in enumerate(valid_loader):
                            results = self.eval_step(*batch)

                            metrics = self._get_metric_results()

                            if old_metrics is not None\
                                    or old_results is not None:
                                # if the old metric or result values are found,
                                # then we use then to merge its values with
                                # the current metric and result values.
                                # LOG.debug(
                                #     'old metrics found: ' + str(old_metrics))
                                # LOG.debug(
                                #     'old results found: ' + str(old_results))
                                metrics = merge_result(old_metrics, metrics)
                                results = merge_result(old_results, results)
                                old_metrics = None
                                old_results = None

                            pbar.loginfo.update(metrics)
                            pbar.log()
                            pbar.step(1)
                            if valid_loader.batch_index % self.partial_ckp_rate == 0:
                                partial_checkpoint(
                                    valid_loader.batch_index,
                                    valid_loader.batch_indices,
                                    results,
                                    metrics,
                                    'valid',
                                 )

                            if not isinstance(results, dict):
                                continue

                            pbar.loginfo.update(results)
                            pbar.loginfo.update()
                            pbar.log()

                        self._update_result(self.valid_results, results)
                        self._update_result(self.valid_results, metrics)
                        self._reset_metrics_state()  # To reset metric state;
                        
                        returned = partial_checkpoint()
                        batch_index = returned[0]
                        batch_indices = returned[1]
                        results = returned[2]
                        metrics = returned[3]
                        step = returned[4]
                except NotImplementedError:
                    LOG.warning(
                        "The evaluation method is not implemented yet."
                    )

            step = 'train'
            partial_checkpoint(step=step)
            finalise_epoch(epoch + 1)
            print("")

        self._run_callback('on_train_end')
        return {"train": self.train_results, "valid": self.valid_results}
